--- unit_test_generator.py	2024-04-12 05:25:59.818468+00:00
+++ unit_test_generator.py	2024-04-12 05:27:22.683430+00:00
@@ -41,32 +41,37 @@
 coverage_cutoff = 100
 recursion_depth_per_decoratee = defaultdict(int)
 
 active = False
 
-def fullname(o:object):
+
+def fullname(o: object):
     """
     Return the "Fully Qualified Name (FQN) of a provided Python
     object. Copied on 21 jAN 2024 directly from Greg Bacon's answer on
     https://stackoverflow.com/questions/2020014/
     """
     module = o.__class__.__module__
     if module is None or module == str.__class__.__module__:
         return o.__class__.__name__
-    return module + '.' + o.__class__.__name__
+    return module + "." + o.__class__.__name__
+
+
 class Jsonable:
     def toJSON(self):
         return self.__dict__
+
 
 class JsonableEncoder(json.JSONEncoder):
     def default(self, obj):
         logger.debug("obj=%s", obj)
         if isinstance(obj, set):
             return sorted(list(obj))
-        #if isinstance(obj, type):
+        # if isinstance(obj, type):
         #    return
         return super().default(obj)
+
 
 # https://pynative.com/make-python-class-json-serializable/
 class FunctionMetaDataEncoder(JSONEncoder):
     def default(self, o):
         if isinstance(o, set):
@@ -77,56 +82,62 @@
             try:
                 return o.__dict__
             except AttributeError:
                 pass
 
+
 def _default(obj):
     if isinstance(obj, set):
         return sorted(list(obj))
     try:
         iterable = iter(obj)
     except TypeError as e:
-        raise  e
+        raise e
     else:
         return list(iterable)
-    #return json.JSONEncoder.default(obj)
+    # return json.JSONEncoder.default(obj)
 
 
 @dataclass
 class CoverageInfo:
     """
     Holds all data gathered from recording/hooking a function/method call
     """
+
     args: list[str] = dataclasses.field(default_factory=list)
     kwargs: dict[str, typing.Any] = dataclasses.field(default_factory=dict)
     globals_before: dict = dataclasses.field(default_factory=dict)
     globals_after: dict = dataclasses.field(default_factory=dict)
-    result: str  = ""
+    result: str = ""
     coverage: list[int] = dataclasses.field(default_factory=list)
     exception_type: str = ""
     exception_message: str = ""
     constructor: str = ""
+
+
 class FunctionMetaData(Jsonable):
     """
     Class to track metadata when testing functions and methods
     """
-    def __init__(   self,
-                    name:str,
-                    lines:list,
-                    is_method:bool,
-                    global_vars_read_from:set,
-                    global_vars_written_to:set,
-                    source_file:Path,
-                    coverage_cost:dict = {},
-                    coverage_io:dict = {},
-                    coverage_percentage:float=0.0,
-                    result_types:dict = {},
-                    test_coverage:dict = {},
-                    types_in_use:set = set(),
-                    unified_test_coverage:set = set(),
-                    needs_pytest:bool = False
-                ):
+
+    def __init__(
+        self,
+        name: str,
+        lines: list,
+        is_method: bool,
+        global_vars_read_from: set,
+        global_vars_written_to: set,
+        source_file: Path,
+        coverage_cost: dict = {},
+        coverage_io: dict = {},
+        coverage_percentage: float = 0.0,
+        result_types: dict = {},
+        test_coverage: dict = {},
+        types_in_use: set = set(),
+        unified_test_coverage: set = set(),
+        needs_pytest: bool = False,
+    ):
         # These properties are always provided
         self.name = name
         self.lines = lines
         self.is_method = is_method
         self.global_vars_read_from = global_vars_read_from
@@ -140,59 +151,62 @@
         self.coverage_percentage = coverage_percentage
         self.result_types = {} if not result_types else result_types
         self.test_coverage = {} if not test_coverage else test_coverage
         self.types_in_use = set() if not types_in_use else types_in_use
         # Change in style simply to keep line length below 80 characters
-        self.unified_test_coverage = set() if unified_test_coverage == set() else unified_test_coverage
+        self.unified_test_coverage = (
+            set() if unified_test_coverage == set() else unified_test_coverage
+        )
         self.needs_pytest = needs_pytest
 
-        #self.exceptions = exceptions
+        # self.exceptions = exceptions
         # This last property is created programmatically
-        self.non_code_lines:set = self.return_non_code_lines()
-
-    def percent_covered(self, precision:int=2):
+        self.non_code_lines: set = self.return_non_code_lines()
+
+    def percent_covered(self, precision: int = 2):
         """
         Compute and return percent of covered lines,
         rounded to 'precision' digits.
         """
         self.unified_test_coverage = set(self.lines) & self.unified_test_coverage
-        pct = len(self.unified_test_coverage)/len(self.lines)
-        pct = round(100*pct, precision)
+        pct = len(self.unified_test_coverage) / len(self.lines)
+        pct = round(100 * pct, precision)
         return pct
 
     def get_all_uncovered_line_str(self):
         """
         Return a string representing the uncovered lines
         All those lines not covered by ANY of the tests
         """
         uncovered = set(self.lines)
         for _, record in self.coverage_io.items():
             uncovered -= set(record.coverage)
-        logger.debug("uncovered=%s self.non_code_lines=%s", uncovered, self.non_code_lines)
+        logger.debug(
+            "uncovered=%s self.non_code_lines=%s", uncovered, self.non_code_lines
+        )
         if uncovered:
             result = coverage_str_helper(list(uncovered), self.non_code_lines)
         else:
             result = uncovered
         logger.debug("result=%s", result)
         return result
 
-
     def __str__(self):
         return f"{self.name}:\n{self.lines=}\n"
 
     def return_non_code_lines(self):
         first_source_line_num = self.lines[0]
         last_source_line_num = self.lines[-1]
-        range_source_line_nums =   set([x for x in range(first_source_line_num,
-                                                        last_source_line_num+1)
-                                        ])
+        range_source_line_nums = set(
+            [x for x in range(first_source_line_num, last_source_line_num + 1)]
+        )
 
         non_code_lines = range_source_line_nums - set(self.lines)
         return non_code_lines
 
-    def repr(self)->str:
-        result = [f"FunctionMetaData(\"{self.name}\""]
+    def repr(self) -> str:
+        result = [f'FunctionMetaData("{self.name}"']
         result.append(self.lines.__repr__())
         result.append(self.is_method.__repr__())
         result.append(self.global_vars_read_from.__repr__())
         result.append(self.global_vars_written_to.__repr__())
         result.append(self.source_file.__repr__())
@@ -202,13 +216,13 @@
         result.append(self.result_types.__repr__())
         result.append(self.test_coverage.__repr__())
         result.append(self.types_in_use.__repr__())
         result.append(self.unified_test_coverage.__repr__())
         result.append(self.needs_pytest.__repr__())
-        result.append(')')
+        result.append(")")
         logger.debug("result=%s", result)
-        return ','.join(result)
+        return ",".join(result)
 
     def __repr__(self) -> str:
         return self.repr()
 
     def purge_record(self, hash_key):
@@ -220,11 +234,11 @@
 
         update_fields = [
             self.coverage_cost,
             self.coverage_io,
             self.result_types,
-            self.test_coverage
+            self.test_coverage,
         ]
         for field in update_fields:
             try:
                 field.pop(hash_key)
             except KeyError as e:
@@ -239,17 +253,18 @@
     # https://stackoverflow.com/questions/3768895
     def to_json(self):
         """
         Convert this class to a json-string
         """
-        return json.dumps(self, default=lambda o: o.__dict__,
-            sort_keys=True, indent=4)
-
-
-def unit_test_generator_decorator(percent_coverage: Optional[int]=0,
-                                  sample_count: Optional[int]=0,
-                                  keep_subsets: bool=False):
+        return json.dumps(self, default=lambda o: o.__dict__, sort_keys=True, indent=4)
+
+
+def unit_test_generator_decorator(
+    percent_coverage: Optional[int] = 0,
+    sample_count: Optional[int] = 0,
+    keep_subsets: bool = False,
+):
     """
     Decorate a function F by recording inputs and outputs during execution such
     that a call to generate_all_tests_and_metadata() can use those recorded
     inputs and outputs to programmatically generate unit tests for F.
     This adds a lot of time and computation in overhead.
@@ -269,11 +284,12 @@
     Any value over 100 will record ALL executions.
     2. sample_count: Record the inputs and output of N unique calls to this
     function, then stop recording them.
     3. If neither of the above are specified, the decorator will NOT be applied.
     """
-    def actual_decorator(func:Callable):
+
+    def actual_decorator(func: Callable):
         """
         Any function wrapped with this decorator will have
         its execution coverage saved as though under a unit test.
         Additionally, all the following will be saved:
         1. All accessed global variables (both read from and written to)
@@ -291,10 +307,11 @@
         monitoring.
 
         When main() completes, main() writes out the coverage results to one file
         per decorated function.
         """
+
         @wraps(func)
         def unit_test_generator_decorator_inner(*args, **kwargs):
             """
             Immediately return function results if:
             1. no stop parameter is specified.
@@ -305,11 +322,11 @@
             """
             func_name = str(func).split()[1]
             if percent_coverage == 0 and sample_count == 0:
                 # The user MUST specify at least one of least values
                 # Don't want to incur the overhead if they don't specify either
-                #logger.error("Neither percent_coverage nor sample_count specified for %s; skip decorator",
+                # logger.error("Neither percent_coverage nor sample_count specified for %s; skip decorator",
                 #            func_name)
                 result = func(*args, **kwargs)
                 return result
 
             global recursion_depth_per_decoratee
@@ -326,13 +343,19 @@
             # A -> B -> A # Does not apply to decorator in 2nd call to A
             for f in inspect.stack()[::-1]:
                 this_frame = inspect.getframeinfo(f[0])
                 function_calls[this_frame.function] += 1
             if func.__name__ not in recursion_depth_per_decoratee:
-                recursion_depth_per_decoratee[func.__name__] = max(function_calls.values())
-
-            elif 1 < max(function_calls.values()) >= recursion_depth_per_decoratee[func.__name__]:
+                recursion_depth_per_decoratee[func.__name__] = max(
+                    function_calls.values()
+                )
+
+            elif (
+                1
+                < max(function_calls.values())
+                >= recursion_depth_per_decoratee[func.__name__]
+            ):
                 try:
                     return func(*args, **kwargs)
                 except Exception as e:
                     logger.critical(e)
                     raise e
@@ -351,71 +374,93 @@
                 # disassemble it to get the lines and global variables
                 if func_name not in all_metadata:
                     # Using single var names ('x', 'y') to keep lines short
                     (x, y, z) = return_function_line_numbers_and_accessed_globals(func)
 
-                    this_metadata = FunctionMetaData(   name=func_name,
-                                                        lines=x,
-                                                        is_method='.' in func_name,
-                                                        global_vars_read_from=y,
-                                                        global_vars_written_to=z,
-                                                        source_file=source_file
-                                                    )
-                    logger.debug("%s has source line #s: %d-%d",
-                                 func_name, min(x), max(x))
+                    this_metadata = FunctionMetaData(
+                        name=func_name,
+                        lines=x,
+                        is_method="." in func_name,
+                        global_vars_read_from=y,
+                        global_vars_written_to=z,
+                        source_file=source_file,
+                    )
+                    logger.debug(
+                        "%s has source line #s: %d-%d", func_name, min(x), max(x)
+                    )
 
                 else:
                     this_metadata = all_metadata[func_name]
 
                 # Check if this decorator should be applied based on the
                 # provided percent_coverage or sample_count variables
-                if percent_coverage and percent_coverage <= this_metadata.percent_covered(0):
+                if (
+                    percent_coverage
+                    and percent_coverage <= this_metadata.percent_covered(0)
+                ):
                     # Desired percent coverage already achieved: skip
-                    logger.info("%d coverage for %s already achieved: skip decorator",
-                                percent_coverage, func_name)
+                    logger.info(
+                        "%d coverage for %s already achieved: skip decorator",
+                        percent_coverage,
+                        func_name,
+                    )
                     # TODO try/catch/raise exception
                     result = func(*args, **kwargs)
                     return result
 
                 if sample_count and sample_count <= len(this_metadata.coverage_io):
                     # Desired number of samples already achieved: skip
-                    logger.info("%d samples for %s already collected: skip decorator",
-                                sample_count, func_name)
+                    logger.info(
+                        "%d samples for %s already collected: skip decorator",
+                        sample_count,
+                        func_name,
+                    )
                     logger.info(this_metadata.coverage_io)
                     # TODO try/catch/raise exception
                     result = func(*args, **kwargs)
                     return result
 
                 # percent_coverage or saple_count properly specified, but
                 # desired coverage/samples not yet achieved
                 # so apply the decorator
                 logger.info("Decorate %s", func_name)
-                return do_the_decorator_thing(func, func_name, this_metadata,
-                                              source_file, keep_subsets,
-                                              *args, **kwargs)
+                return do_the_decorator_thing(
+                    func,
+                    func_name,
+                    this_metadata,
+                    source_file,
+                    keep_subsets,
+                    *args,
+                    **kwargs,
+                )
             except Exception as e:
                 logger.warning("e=%s", e)
-                #raise e
+                # raise e
+
         return unit_test_generator_decorator_inner
+
     return actual_decorator
 
-def _pandas_df_repr(df: pd.DataFrame)->str:
-    '''
+
+def _pandas_df_repr(df: pd.DataFrame) -> str:
+    """
     Sadly, the 'repr' method for Pandas DataFrames does not work the
     same as 'repr' for built-in types.  Specifically, while 'repr' on
     built-in types (strings, lists, dicts, etc) produces valid Python
     code that can be instantly used to re-create the original object,
     this is not true of Pandas DataFrames, which are instead pretty
     printed as a table.  The best alternative for non-empty dataframes is
     https://stackoverflow.com/questions/67845199 by user Silveri
     Overwrite the native Pandas DataFram repr() method with that approach.
-    '''
+    """
     return f"DataFrame.from_dict({df.to_dict()})"
 
-pd.DataFrame.__repr__ = _pandas_df_repr # type: ignore[method-assign, assignment]
-
-def get_module_import_string(my_path:Path)->str:
+
+pd.DataFrame.__repr__ = _pandas_df_repr  # type: ignore[method-assign, assignment]
+
+
+def get_module_import_string(my_path: Path) -> str:
     """
     Given a module, return a dotted import string, the
     fully qualified name to that module, e.g.
     "package.module"
     """
@@ -425,15 +470,20 @@
     this_type = ""
     for file_str in files:
         file = Path(file_str)
         if my_path.is_relative_to(file):
             keep_file = file
-            logger.debug("os.path.relpath(file, my_path, )=%s", 
-                         os.path.relpath(file, my_path, ))
+            logger.debug(
+                "os.path.relpath(file, my_path, )=%s",
+                os.path.relpath(
+                    file,
+                    my_path,
+                ),
+            )
             this_type = f"{os.path.relpath(file, my_path)}"
     if keep_file:
-        my_path_str = str(my_path)[len(str(keep_file)):]
+        my_path_str = str(my_path)[len(str(keep_file)) :]
         my_path_str = re.sub(r"^[\\/]", "", my_path_str)
         this_type = re.sub(".py$", "", my_path_str)
         if not this_type:
             raise Exception("Can't determine type")
         this_type = re.sub(r"\\", ".", this_type)
@@ -441,11 +491,12 @@
         # Other other OS's use forward slashes
         this_type = re.sub(r"/", ".", this_type)
 
     return this_type
 
-def get_class_import_string(arg:typing.Any):
+
+def get_class_import_string(arg: typing.Any):
     """
     Given a class, return a dotted import string, the
     fully qualified name to that class, e.g.
     "package.module.class"
     """
@@ -458,20 +509,21 @@
         file_path = Path(file)
         if my_path.is_relative_to(file_path):
             keep_file = file_path
             this_type = f"{os.path.relpath(file_path, my_path)}"
     if keep_file:
-        my_path_str = str(my_path)[len(str(keep_file)):]
+        my_path_str = str(my_path)[len(str(keep_file)) :]
         my_path_str = re.sub(r"^[\\/]", "", my_path_str)
         this_type = re.sub(".py$", "", my_path_str) + "." + arg.__class__.__qualname__
         this_type = re.sub(r"\\", ".", this_type)
         # Other other OS's use forward slashes
         this_type = re.sub(r"/", ".", this_type)
 
     return this_type
 
-def get_method_class_import_string(arg:typing.Any):
+
+def get_method_class_import_string(arg: typing.Any):
     """
     Given a method, return a dotted import string, the
     fully qualified name to its class, e.g.
     "package.module.class"
     """
@@ -483,18 +535,19 @@
         file = Path(file_str)
         if my_path.is_relative_to(file):
             keep_file = file
             this_type = f"{os.path.relpath(file, my_path)}"
     if keep_file:
-        my_path_str = str(my_path)[len(str(keep_file)):]
+        my_path_str = str(my_path)[len(str(keep_file)) :]
         my_path_str = re.sub(r"^[\\/]", "", my_path_str)
         this_type = re.sub(".py$", "", my_path_str) + "." + arg.__name__
         this_type = re.sub(r"\\", ".", this_type)
         # Other other OS's use forward slashes
         this_type = re.sub(r"/", ".", this_type)
 
     return this_type
+
 
 @unit_test_generator_decorator()
 def sorted_set_repr(obj: set):
     """
     I want sets to appear sorted when initialized in unit tests.
@@ -507,10 +560,11 @@
     obj_set_code = f"{{{obj_list_repr[1:-1]}}}"
     # "obj" is now valid Python code that will create a set.
     # The objects in this line of code appear in sorted order
     return repr(obj_set_code)
 
+
 # TODO Import any modules here for whom 'repr' doesn't work
 from pandas import DataFrame  # noqa: E402
 
 pp = pprint.PrettyPrinter(indent=3)
 
@@ -520,14 +574,20 @@
 # Set this value to disable the
 # unit_test_generator_decorator once coverage hits
 # this value as a percent, e.g. 80 = 80% coverage
 coverage_cutoff = 60
 
-def do_the_decorator_thing(func: Callable, func_name:str,
-                           this_metadata:FunctionMetaData, source_file: str,
-                           keep_subsets: bool=False,
-                             *args, **kwargs):
+
+def do_the_decorator_thing(
+    func: Callable,
+    func_name: str,
+    this_metadata: FunctionMetaData,
+    source_file: str,
+    keep_subsets: bool = False,
+    *args,
+    **kwargs,
+):
     """
     Any function wrapped with this decorator will have
     its execution coverage saved as though under a unit test.
     Additionally, all the following will be saved:
     1. All accessed global variables (both read from and written to)
@@ -547,35 +607,34 @@
     When main() completes, main() writes out the coverage results to one file
     per decorated function.
     """
     global all_metadata, hashed_inputs
     caught_exception = None
-    if 'kwargs' in kwargs:
-        kwargs = kwargs['kwargs']
-
-    #logger.critical(f"Decorating {func_name}".center(80, '-'))
-
-    '''
+    if "kwargs" in kwargs:
+        kwargs = kwargs["kwargs"]
+
+    # logger.critical(f"Decorating {func_name}".center(80, '-'))
+
+    """
     if func_name in all_metadata and\
         all_metadata[func_name].coverage_percentage >= coverage_cutoff:
         logger.debug(f"Hit >={coverage_cutoff=} in {func_name}; skip it.")
         x = func(*args, **kwargs)
         #logger.critical(f"Undecorating {func_name}".center(80, '-'))
         return x
-    '''
-
+    """
 
     if "pytest" in sys.modules:
         logger.debug("pytest is loaded; don't decorate when under a test")
         x = func(*args, **kwargs)
-        #logger.critical(f"Undecorating {func_name}".center(80, '-'))
+        # logger.critical(f"Undecorating {func_name}".center(80, '-'))
         return x
 
     this_coverage_info: CoverageInfo = CoverageInfo()
 
-    #args_copy = [convert_to_serializable(x) for x in args]
-    args_copy:list[str] = []
+    # args_copy = [convert_to_serializable(x) for x in args]
+    args_copy: list[str] = []
     class_type = None
     if this_metadata.is_method and not func_name.endswith("__init__"):
         logger.critical("%s", func_name)
         this_coverage_info.constructor = args[0].repr()
 
@@ -587,13 +646,18 @@
     for arg_i, arg in enumerate(args):
         # Do not include the first arg of a method (it's "self")
         # in the argument list
         if this_metadata.is_method and arg_i == 0:
             continue
-        if callable(arg) and  inspect.isfunction(arg) and "." in arg.__qualname__ and arg.__qualname__[0].isupper():
-            newest_import_list = f"{arg.__module__}.{arg.__qualname__}".split('.')
-            newest_import = '.'.join(newest_import_list[:-1])
+        if (
+            callable(arg)
+            and inspect.isfunction(arg)
+            and "." in arg.__qualname__
+            and arg.__qualname__[0].isupper()
+        ):
+            newest_import_list = f"{arg.__module__}.{arg.__qualname__}".split(".")
+            newest_import = ".".join(newest_import_list[:-1])
             args_copy.append(arg.__qualname__)
             try:
                 # Reset the class type, as this newes_import will be used
                 # instead
                 class_type = None
@@ -601,13 +665,14 @@
                     file_name_match = re.search(r"([\w]+).py", str(arg.__code__))
                     if file_name_match:
                         file_name = str(file_name_match.groups()[0])
                         newest_import = re.sub("__main__", file_name, newest_import)
                     else:
-                        logger.critical("NO FILENAME FOUND!: %s", re.escape(str(arg.__code__)))
+                        logger.critical(
+                            "NO FILENAME FOUND!: %s", re.escape(str(arg.__code__))
+                        )
                 new_types_in_use.add(newest_import)
-
 
             except Exception as e:
                 print(traceback.format_exc())
                 logger.critical(e)
                 sys.exit(2)
@@ -620,42 +685,53 @@
         if callable(arg):
             if arg.__module__ == "__main__":
                 file_name_match = re.search(r"([\w]+).py", str(arg.__code__))
                 if file_name_match:
                     file_name = file_name_match.groups()[0]
-                    logger.debug("%s.%s",file_name, arg.__name__)
+                    logger.debug("%s.%s", file_name, arg.__name__)
                     args_copy.append(f"{file_name}.{arg.__name__}")
                 else:
-                    logger.critical("NO FILENAME FOUND!: %s", re.escape(str(arg.__code__)))
+                    logger.critical(
+                        "NO FILENAME FOUND!: %s", re.escape(str(arg.__code__))
+                    )
             else:
                 args_copy.append(arg.__qualname__)
 
-            #sys.exit(1)
+            # sys.exit(1)
         elif not isinstance(arg, str):
             type_str = str(type(arg))
-            #logger.critical(arg)
-            #logger.debug(f"{type_str} {type(arg).__module__}")
+            # logger.critical(arg)
+            # logger.debug(f"{type_str} {type(arg).__module__}")
 
             # Reference for line:
             # 'type(arg).__module__ != "__builtin__":'
             # https://stackoverflow.com/questions/46876484/
             # Answer by user moar10
-            if bool(re.match(r"<class[^\.]+\.", type_str)) and\
-                type(arg).__module__ != "__builtin__":
+            if (
+                bool(re.match(r"<class[^\.]+\.", type_str))
+                and type(arg).__module__ != "__builtin__"
+            ):
                 try:
                     class_repr = arg.repr()
 
                 except AttributeError:
                     class_repr = arg.__repr__()
-                #logger.debug(f"Got class!: {class_repr}")
+                # logger.debug(f"Got class!: {class_repr}")
                 try:
                     logger.info(class_repr)
                     eval(class_repr)
                     args_copy.append(class_repr)
                 except SyntaxError as e:
                     # skip on error
-                    logger.debug("Got %s %s decorating %s repr'ing arg=%s:\ne=%s", type(e), class_repr, func_name, arg, e)
+                    logger.debug(
+                        "Got %s %s decorating %s repr'ing arg=%s:\ne=%s",
+                        type(e),
+                        class_repr,
+                        func_name,
+                        arg,
+                        e,
+                    )
                     x = func(*args, **kwargs)
                     all_metadata[func_name] = this_metadata
                     return x
                 except NameError as e:
                     # What's going on here?
@@ -669,11 +745,11 @@
 
                     args_copy.append(class_repr)
             else:
                 args_copy.append(repr(arg))
         else:
-            args_copy.append("\""+re.sub(r"(?<!\\) \"", r'\\"',arg)+"\"")
+            args_copy.append('"' + re.sub(r"(?<!\\) \"", r'\\"', arg) + '"')
 
     if class_type:
         this_metadata.types_in_use.add(class_type)
     this_metadata.types_in_use |= new_types_in_use
 
@@ -700,11 +776,11 @@
 
     if kwargs:
         this_coverage_info.kwargs = kwargs
 
     try:
-        hashed_input_hash = hashlib.new('sha256')
+        hashed_input_hash = hashlib.new("sha256")
         hashed_input_hash.update(str(this_coverage_info.globals_before).encode())
         hashed_input_hash.update(str(this_coverage_info.args).encode())
         hashed_input_hash.update(str(this_coverage_info.kwargs).encode())
         hashed_input = hashed_input_hash.hexdigest()
     except Exception as e:
@@ -739,58 +815,60 @@
                 start_time = time.perf_counter()
                 result = func(*args)
 
             logger.debug("No exception :)")
         except Exception as e:
-            #this_metadata.exceptions[hash_key] = e
+            # this_metadata.exceptions[hash_key] = e
             logger.debug("Caught e=%s", e)
             caught_exception = e
-            #raise caught_exception'
+            # raise caught_exception'
         finally:
             end_time = time.perf_counter()
     with Capturing() as stdout_lines:
-        cov.json_report(outfile='-')
+        cov.json_report(outfile="-")
     # result will not exist if the function threw an exception
     cov_report_ = json.loads(stdout_lines[0])
-    #hashed_input = f"{func_name}_{time.time_ns()}"#cov_report_['meta']['hash_key']
+    # hashed_input = f"{func_name}_{time.time_ns()}"#cov_report_['meta']['hash_key']
     if caught_exception:
-        logger.debug("caught_exception=%s @ %s result=%s", caught_exception, hashed_input, result)
+        logger.debug(
+            "caught_exception=%s @ %s result=%s", caught_exception, hashed_input, result
+        )
 
     result_type = str(type(result))
     parsed_type = re.match("<class '([^']+)'>", result_type)
     if parsed_type:
         result_type = parsed_type.groups()[0]
 
     this_metadata.types_in_use |= get_all_types("4", result)
-    #assert hashed_input not in hashed_inputs, "ALREADY"
+    # assert hashed_input not in hashed_inputs, "ALREADY"
     this_metadata.result_types[hashed_input] = result_type
-    #hash_keys.add(hash_keys)
+    # hash_keys.add(hash_keys)
 
     # There is only one file in cov_report_['files']
-    assert len(cov_report_['files']) == 1
-    this_coverage = set(cov_report_['files'].popitem()[1]['executed_lines'])
+    assert len(cov_report_["files"]) == 1
+    this_coverage = set(cov_report_["files"].popitem()[1]["executed_lines"])
     assert this_coverage & set(this_metadata.lines)
-    #logger.critical("this_coverage=%s", this_coverage)
+    # logger.critical("this_coverage=%s", this_coverage)
     is_subset = False
     Path.unlink(Path(data_file))
 
     # If no new lines were covered, do nothing else,
     # but just immediately return the result
 
     pct_covered = this_metadata.percent_covered()
     pct_covered = round(pct_covered, 4)
-    delta = len(this_coverage-this_metadata.unified_test_coverage)
+    delta = len(this_coverage - this_metadata.unified_test_coverage)
 
     if delta == 0 and not keep_subsets:
         all_metadata[func_name] = this_metadata
         logger.debug("No new coverage decorating %s; but not skipping.", func_name)
         if caught_exception:
             raise caught_exception
         return result
 
     pct_improvement = delta / len(this_metadata.lines)
-    pct_improvement = round(100*pct_improvement, 4)
+    pct_improvement = round(100 * pct_improvement, 4)
 
     log_message = f"{func_name=}; {len(this_coverage)=}"
     logger.debug(log_message)
     log_message = f"({pct_covered=}%) ({delta=}) {pct_improvement=}"
     logger.debug(log_message)
@@ -812,19 +890,22 @@
         # of the lines covered by this test
         if prev_coverage.issubset(this_coverage):
             logger.debug("%s removing subset coverage @ %s.", source_file, key)
             this_metadata.test_coverage.pop(key)
 
-
     # Put another way, only keep these results IF the test coverage
     # here is NOT a subset of ANY previous run
     if is_subset:
         all_metadata[func_name] = this_metadata
         if caught_exception:
             raise caught_exception
-        logger.debug("%s coverage is a subset this_metadata.coverage_percentage=%s", func_name, this_metadata.coverage_percentage)
-        #logger.critical(f"Undecorating {func_name}".center(80, '-'))
+        logger.debug(
+            "%s coverage is a subset this_metadata.coverage_percentage=%s",
+            func_name,
+            this_metadata.coverage_percentage,
+        )
+        # logger.critical(f"Undecorating {func_name}".center(80, '-'))
         return result
 
     logger.debug("%s coverage @%s is not a subset", func_name, hashed_input)
 
     if caught_exception:
@@ -865,91 +946,101 @@
     # TODO remove this deepcopy
     this_metadata.coverage_io[hashed_input] = copy.deepcopy(this_coverage_info)
     this_metadata.coverage_cost[hashed_input] = round(end_time - start_time, 3)
     this_metadata.test_coverage[hashed_input] = this_coverage
 
-    #print("Cost")
-    #pp.pprint(coverage_cost)
+    # print("Cost")
+    # pp.pprint(coverage_cost)
 
     if caught_exception:
         all_metadata[func_name] = this_metadata
         raise caught_exception
-    #logger.critical(f"Undecorating {func_name}".center(80, '-'))
+    # logger.critical(f"Undecorating {func_name}".center(80, '-'))
 
     all_metadata[func_name] = this_metadata
     return result
 
 
-
-all_metadata:defaultdict[str, FunctionMetaData] = defaultdict(FunctionMetaData) # type: ignore[arg-type]
-hashed_inputs:set[str] = set() # method-assign
+all_metadata: defaultdict[str, FunctionMetaData] = defaultdict(FunctionMetaData)  # type: ignore[arg-type]
+hashed_inputs: set[str] = set()  # method-assign
+
 
 class Capturing(list):
-    '''
+    """
     Use to capture STDOUT output
-    '''
+    """
+
     # Source https://stackoverflow.com/questions/16571150
     # By users kindall and Antti Haapala
     def __enter__(self):
         self._stdout = sys.stdout
         sys.stdout = self._stringio = StringIO()
         return self
+
     def __exit__(self, *args):
         self.extend(self._stringio.getvalue().splitlines())
-        del self._stringio    # free up some memory
+        del self._stringio  # free up some memory
         sys.stdout = self._stdout
+
 
 def capture(f):
     """
     Decorator to capture standard output
     from https://stackoverflow.com/questions/33160744
     """
+
     def captured(*args, **kwargs):
         # setup the environment
         backup = sys.stdout
         try:
-            sys.stdout = StringIO()     # capture output
+            sys.stdout = StringIO()  # capture output
             f(*args, **kwargs)
-            out = sys.stdout.getvalue() # release output
+            out = sys.stdout.getvalue()  # release output
         finally:
             sys.stdout.close()  # close the stream
-            sys.stdout = backup # restore original stdout
-        return out # captured output wrapped in a string
+            sys.stdout = backup  # restore original stdout
+        return out  # captured output wrapped in a string
+
     return captured
 
+
 # Decorating yields recursion exception
-def is_global_var(this_global:str, function_globals:dict, func_name:str):
+def is_global_var(this_global: str, function_globals: dict, func_name: str):
     """
     Not all global "variables" LOADed are relevant, some are just
     imported modules (e.g. os, sys, re, etc). Given a the name of a
     candidate global variable (i.e. variables LOADed or STOREd via
     LOAD_GLOBAL or STORE_GLOBAL bytecodes) and
     the 'f'unction associated with the candidate, return True if the
     candidate is not a function or module.
     """
     is_variable = False
-    undesired_types = ["<class 'function'>","<class 'module'>"]
+    undesired_types = ["<class 'function'>", "<class 'module'>"]
     # TODO: Find a better way to do this than a str compare!
-    if this_global in function_globals and \
-        str(type(function_globals[this_global])) not in undesired_types:
-        #logger.debug(f"Adding {this_global}, {type(function_globals[this_global])=}")
+    if (
+        this_global in function_globals
+        and str(type(function_globals[this_global])) not in undesired_types
+    ):
+        # logger.debug(f"Adding {this_global}, {type(function_globals[this_global])=}")
         is_variable = True
-    elif this_global in function_globals and \
-    isinstance(function_globals[this_global], types.ModuleType):
+    elif this_global in function_globals and isinstance(
+        function_globals[this_global], types.ModuleType
+    ):
         logger.debug("Got import for %s this_gloabl=%s", func_name, this_global)
     return is_variable
+
 
 @unit_test_generator_decorator()
 def return_function_line_numbers_and_accessed_globals(f: Callable):
     """
     Given a function, returns three sets:
     1. a set of the line numbers of this function's source code
     2. all global vars read by the provided function
     3. all global vars written to by the provided function
     """
     try:
-        f = f.__wrapped__ # type: ignore [attr-defined]
+        f = f.__wrapped__  # type: ignore [attr-defined]
     except AttributeError:
         pass
     line_numbers = []
 
     global_vars_read_from = set()
@@ -971,16 +1062,13 @@
                 global_vars_read_from.add(this_global)
         elif "STORE_GLOBAL" in line:
             this_global = line.split("(")[1].split(")")[0]
             if is_global_var(this_global, f.__globals__, f.__name__):
                 global_vars_written_to.add(this_global)
-    result = [
-                line_numbers,
-                global_vars_read_from,
-                global_vars_written_to
-            ]
+    result = [line_numbers, global_vars_read_from, global_vars_written_to]
     return result
+
 
 @unit_test_generator_decorator()
 def count_objects(obj: typing.Any):
     """
     Given a Python object, e.g. a number, string, list, list of lists,
@@ -1018,18 +1106,19 @@
         except TypeError:
             # If the object isn't a str or iterable, treat it as one object
             count += 1
     return count
 
-def get_all_types(loc: str, obj, import_modules:bool=True)->set:
+
+def get_all_types(loc: str, obj, import_modules: bool = True) -> set:
     """
     Return the set of all types contained in this object,
     It might be a list of sets so return {"list", "set"}
     """
     all_types = set()
     type_str = str(type(obj))
-    type_list =  ['str', 'int', 'list', 'set', 'dictionry', 'dict']
+    type_list = ["str", "int", "list", "set", "dictionry", "dict"]
     if not any(x in type_str for x in type_list):
         logger.debug("%s type_str=%s", loc, type_str)
     if callable(obj):
         if hasattr(obj, "__code__"):
             logger.debug("%s %s.%s as callable", loc, obj.__module__, obj.__name__)
@@ -1055,16 +1144,19 @@
         elif import_modules:
             logger.debug("%s %s missing __code__ < I need this module!", loc, obj)
         else:
             logger.debug("%s type_str=%s < I need this FQDN!", loc, type_str)
 
-
     elif "." in type_str:
         if import_modules:
-            logger.debug("%s type_str=%s < I need this non-callable module!", loc, type_str)
+            logger.debug(
+                "%s type_str=%s < I need this non-callable module!", loc, type_str
+            )
         else:
-            logger.debug("%s type_str=%s < I need this non-callable FQDN!", loc, type_str)
+            logger.debug(
+                "%s type_str=%s < I need this non-callable FQDN!", loc, type_str
+            )
             parsed_type_match = re.match("<class '([^']+)'>", type_str)
             if parsed_type_match:
                 parsed_type = parsed_type_match.groups()[0]
                 if parsed_type and parsed_type.startswith("__main__"):
                     ext_module_file = inspect.getfile(obj.__class__)
@@ -1079,11 +1171,11 @@
 
                 return set([parsed_type])
 
     if isinstance(obj, dict):
         for v in obj.values():
-            #all_types.add(type(k))
+            # all_types.add(type(k))
             all_types |= get_all_types("6", v, import_modules)
 
     # Now handle all other iterables aside from dictionaries
     # Non-iterables will throw a TypeError but that's perfectly ok
     elif not isinstance(obj, str):
@@ -1104,15 +1196,17 @@
     if result:
         logger.debug("result=%s", result)
     return result
 
 
-def generate_all_tests_and_metadata_helper( local_all_metadata:dict,
-                                            func_names:list[str],
-                                            outdir:Path,
-                                            tests_dir:Path,
-                                            suffix:Path=Path(".json")):
+def generate_all_tests_and_metadata_helper(
+    local_all_metadata: dict,
+    func_names: list[str],
+    outdir: Path,
+    tests_dir: Path,
+    suffix: Path = Path(".json"),
+):
     """
     This function generates units tests for decorated functions and methods.
 
     Because I also decorate functions within this very file
     (i.e. the functions and methods that implement the automatic unit
@@ -1123,60 +1217,65 @@
     I do claim this is self-testing code after all!
     """
 
     for func_name in func_names:
         logger.debug("func_name=%s", func_name)
-        function_metadata:FunctionMetaData = copy.deepcopy(local_all_metadata[func_name])
+        function_metadata: FunctionMetaData = copy.deepcopy(
+            local_all_metadata[func_name]
+        )
         coverage_io_keys = copy.deepcopy(list(function_metadata.coverage_io.keys()))
 
         # TODO Fix bug here where function_metadata.coverage_io dictionaries
         # are shared for multiple functions within this file.
         # Patched for now by making a deep copy of each in the lines above,
         # but it feels hacky.
         purged = 0
 
         # TODO The below below is likely unnecessary now
         for hash_key in coverage_io_keys:
-            if not set(function_metadata.coverage_io[hash_key].coverage) & set(function_metadata.lines):
+            if not set(function_metadata.coverage_io[hash_key].coverage) & set(
+                function_metadata.lines
+            ):
                 purged += 1
                 function_metadata.purge_record(hash_key)
                 function_metadata.unified_test_coverage = set()
 
         if purged:
             for _, cov in function_metadata.test_coverage.items():
                 function_metadata.unified_test_coverage |= set(cov)
-            #function_metadata.percent_covered = function_metadata.percent_covered(2)
+            # function_metadata.percent_covered = function_metadata.percent_covered(2)
 
         test_suite = function_metadata.coverage_io
-        '''
+        """
         The json file is optional and unused but makes for
         friendly reading of the inputs to the unit test if
         the actual .py unit test file is hard to read
         due to formatting.
-        '''
+        """
         this_func_name = re.sub(".__init__", ".constructor", func_name)
         filename = outdir.joinpath(f"{this_func_name}{suffix}")
         with open(filename, "w", encoding="utf-8") as test_io_file:
             logger.info("Dumping test metadata to %s...", str(filename))
-            json.dump(function_metadata,
-                      test_io_file,
-                      cls=FunctionMetaDataEncoder,
-                      indent=3
-                      )
-
-        auto_generate_tests(local_all_metadata[func_name],
-                            test_suite,
-                            func_name,
-                            function_metadata.source_file,
-                            tests_dir)
+            json.dump(
+                function_metadata, test_io_file, cls=FunctionMetaDataEncoder, indent=3
+            )
+
+        auto_generate_tests(
+            local_all_metadata[func_name],
+            test_suite,
+            func_name,
+            function_metadata.source_file,
+            tests_dir,
+        )
         local_all_metadata.pop(func_name)
     return local_all_metadata
 
+
 @unit_test_generator_decorator()
-def generate_all_tests_and_metadata(outdir:Path,
-                                    tests_dir:Path,
-                                    suffix:Path=Path(".json")):
+def generate_all_tests_and_metadata(
+    outdir: Path, tests_dir: Path, suffix: Path = Path(".json")
+):
     """
     Called once the ad-hoc/integration/regression tests
     are completed, this function writes all the results
     of using the unit_test_generator_decorator() decorator
     to files, one file per decorated function.
@@ -1193,50 +1292,48 @@
     to test the functions and methods defined in this
     file and called by generate_all_tests_and_metadata_helper()
     """
     for phase in ["Before", "After"]:
         logger.debug("phase=%s", phase)
-        #pp.pprint(all_metadata)
+        # pp.pprint(all_metadata)
 
         logger.debug("%s: %s", phase, all_metadata.keys())
 
         func_names = copy.deepcopy(list(all_metadata.keys()))
         local_all_metadata = all_metadata
-        local_all_metadata = generate_all_tests_and_metadata_helper(local_all_metadata,
-                                                                    func_names,
-                                                                    outdir,
-                                                                    tests_dir,
-                                                                    suffix)
+        local_all_metadata = generate_all_tests_and_metadata_helper(
+            local_all_metadata, func_names, outdir, tests_dir, suffix
+        )
+
 
 @unit_test_generator_decorator()
-def update_global(obj, this_global:str, 
-                  phase:str,this_coverage_info:CoverageInfo)->CoverageInfo:
+def update_global(
+    obj, this_global: str, phase: str, this_coverage_info: CoverageInfo
+) -> CoverageInfo:
     """
     Update and return state dictionary with new global.
     """
     if isinstance(obj, set):
         this_entry = sorted_set_repr(obj)
     else:
         this_entry = repr(obj)
     # The block below is for a separate project
-    #if this_global == "g_function_params_write_locs":
-        #logger.critical(f"{this_global=}\n{obj=}")
+    # if this_global == "g_function_params_write_locs":
+    # logger.critical(f"{this_global=}\n{obj=}")
     if this_entry.startswith("<"):
         return this_coverage_info
-    #print(f"{this_global}={this_entry}")
+    # print(f"{this_global}={this_entry}")
 
     if phase == "Before":
         this_coverage_info.globals_before[this_global] = this_entry
-    elif phase == 'After':
+    elif phase == "After":
         this_coverage_info.globals_after[this_global] = this_entry
     return this_coverage_info
 
 
-
-
 @unit_test_generator_decorator()
-def normalize_arg(arg:typing.Any):
+def normalize_arg(arg: typing.Any):
     """
     Convert arg to "canonical" form; i.e. convert it to a string format such
     that by writing it to a file it becomes proper Python code.
     """
     if isinstance(arg, str):
@@ -1248,12 +1345,13 @@
     # Trim quotes so types are used rather than just the string representation
     if isinstance(arg, str) and arg[0] == '"' and arg[-1] == '"':
         arg = arg[1:-1]
     return arg
 
+
 @unit_test_generator_decorator()
-def coverage_str_helper(this_list:list, non_code_lines:set)->list:
+def coverage_str_helper(this_list: list, non_code_lines: set) -> list:
     """
     Given a 'this_list', containing numbers covered or uncovered,
     and a set of non_code_lines (comments or whitespace),
     Generate a list that compactly represents the (un) covered lines.
     e.g.
@@ -1295,24 +1393,27 @@
         else:
             logger.critical("Invalid coverage! %s", this_list)
 
     return results_list
 
+
 @unit_test_generator_decorator()
-def gen_coverage_list(  function_metadata:FunctionMetaData,
-                        coverage_list:list,
-                        func_name:str,
-                        tab:str=" "*3):
+def gen_coverage_list(
+    function_metadata: FunctionMetaData,
+    coverage_list: list,
+    func_name: str,
+    tab: str = " " * 3,
+):
     """
     Given a state[hash_key] and function name create a comment string
     to show lines covered, percent covered, and lines not covered
     """
     first_source_line_num = function_metadata.lines[0]
     last_source_line_num = function_metadata.lines[-1]
-    range_source_line_nums =   set([x for x in range(first_source_line_num,
-                                                     last_source_line_num+1)
-                                    ])
+    range_source_line_nums = set(
+        [x for x in range(first_source_line_num, last_source_line_num + 1)]
+    )
     coverage_set = set(coverage_list)
     coverage_list = sorted(list(range_source_line_nums & coverage_set))
     if not coverage_list:
         logger.warning("Fix the bug here; no coverage for %s", func_name)
         return []
@@ -1323,18 +1424,18 @@
     logger.debug("func_name=%s", func_name)
     if logger.level >= logging.DEBUG:
         msg = pp.pformat(function_metadata.lines)
         logger.debug("lines=%s", msg)
 
-    percent_covered = 100*len(coverage_list)/len(function_metadata.lines)
-    #percent_covered = 100*percent_covered
+    percent_covered = 100 * len(coverage_list) / len(function_metadata.lines)
+    # percent_covered = 100*percent_covered
     coverage_str_list = []
     start_list = []
     start_list.append(f"{tab}# Coverage: {percent_covered:.2f}% of function lines ")
     start_list.append(f"[{first_source_line_num}-{last_source_line_num}]\n")
     start_list.append(f"{tab}# Covered Lines: ")
-    start = ''.join(start_list)
+    start = "".join(start_list)
     uncovered_str_list = []
     start2 = f"{tab}# Lines not covered: "
     # Create the uncovered list now for use laster in this function
     uncovered = sorted(list(range_source_line_nums - set(coverage_list)))
 
@@ -1352,16 +1453,15 @@
     logger.debug(coverage_str_list)
     result = [f"\n{start}{';'.join(coverage_str_list)}"]
     result.append(f"\n{start2}{';'.join(uncovered_str_list)}\n{end}")
     return result
 
+
 @unit_test_generator_decorator()
-def meta_program_function_call( this_state:CoverageInfo,
-                                tab:str,
-                                package,
-                                func_name:str,
-                                result_type:str):
+def meta_program_function_call(
+    this_state: CoverageInfo, tab: str, package, func_name: str, result_type: str
+):
     """
     Given the provided arguments,
     return a list of valid Python code that executes the decorated
     function and asserts that the result is as expected.
     """
@@ -1370,78 +1470,84 @@
     test_str_list = []
 
     # Handle the case that decoratee is a
     # class method by constructing the class
     if this_state.constructor:
-        func_name=func_name.split('.')[1]
+        func_name = func_name.split(".")[1]
         class_var_name = "this_class"
-        is_method = True # Marginally faster than this string compare?
+        is_method = True  # Marginally faster than this string compare?
         line = f"{tab}{class_var_name} = {this_state.constructor}\n"
         test_str_list.append(line)
 
-    kwargs_str = ''
+    kwargs_str = ""
     # TODO: Test this block below
     if this_state.kwargs:
         # Creating "line" variable to condense line width
         line = f"{tab}kwargs = {this_state.kwargs}\n"
         test_str_list.append(line)
         kwargs_str = ", kwargs=kwargs)"
-        #line = f"{tab}x = {package}.{func_name}(*args, kwargs=kwargs)\n"
-        #test_str_list.append(line)
+        # line = f"{tab}x = {package}.{func_name}(*args, kwargs=kwargs)\n"
+        # test_str_list.append(line)
 
     assignment = f"{tab}x = "
     call = ""
     if is_method:
         call = f"{class_var_name}.{func_name}(*args{kwargs_str})\n"
     else:
         call = f"{package}.{func_name}(*args{kwargs_str})\n"
 
     if this_state.exception_type:
         e_type = this_state.exception_type
-        e_type =  re.search("<class '([^']+)'", e_type).groups()[0] # type: ignore[union-attr]
+        e_type = re.search("<class '([^']+)'", e_type).groups()[0]  # type: ignore[union-attr]
         e_str = this_state.exception_message
         # Any special chars, e.g. an empty list: [] in the e_str will break
         # the pytest.raise() parser, so use re.escape()
         e_str = re.escape(e_str)
 
         # Source: https://docs.pytest.org/en/6.2.x/assert.html#assertraises
-        line = f'{tab}with pytest.raises({e_type}, match=r\"{e_str}\"):\n'
+        line = f'{tab}with pytest.raises({e_type}, match=r"{e_str}"):\n'
         test_str_list.append(line)
-        line = f'{tab*2}{call}'
+        line = f"{tab*2}{call}"
         test_str_list.append(line)
     else:
         normal_call = f"{assignment}{call}"
         if func_name.endswith(".__init__"):
-            #func_name = re.sub(".__init__", "", func_name)
+            # func_name = re.sub(".__init__", "", func_name)
             normal_call = re.sub(".__init__", "", normal_call)
         test_str_list.append(normal_call)
         if not this_state.result:
             line = f"{tab}assert not x\n"
         else:
             result_str = ""
             logger.debug("func_name=%s", func_name)
             if result_type == "str":
                 logger.debug("String: %s", this_state)
                 x = this_state.result.replace("'", "\\'").replace('"', '\\"')
-                result_str = f"\'{x}\'"
+                result_str = f"'{x}'"
             else:
                 result_str = this_state.result
                 result_str = normalize_arg(this_state.result)
             assert not result_str.startswith("'\n"), "Bad juju"
-            #line = f"{tab}assert x == {result_str}\n"
+            # line = f"{tab}assert x == {result_str}\n"
             if func_name.endswith(".__init__"):
                 class_fqn = re.sub(".__init__.*$", "", call)
                 line = f"{tab}assert isinstance(x, {class_fqn})\n"
             else:
                 line = f"{tab}assert x == {result_str}\n"
         test_str_list.append(line)
     return test_str_list
 
+
 @unit_test_generator_decorator()
-def auto_generate_tests(function_metadata:FunctionMetaData,
-                        state:dict, func_name:str, source_file:Path,
-                        tests_dir:Path, indent_size:int=2):
+def auto_generate_tests(
+    function_metadata: FunctionMetaData,
+    state: dict,
+    func_name: str,
+    source_file: Path,
+    tests_dir: Path,
+    indent_size: int = 2,
+):
     """
     This is the function that can automatically create a unit
     test file for each decorated function.
     The contents of the unit test file(s) are created by appending
     to lists of strings, these lists of strings are evenutally
@@ -1451,127 +1557,128 @@
     was_executed = False
     # TODO Add to the import list any specific modules for
     # which repr doesn't work, e.g.
     # imports.append(import pandas as pd\n")
 
-    tab = " "*indent_size
+    tab = " " * indent_size
     header = []
     pct = function_metadata.coverage_percentage
-    #assert pct <= 100, "Bad math"
+    # assert pct <= 100, "Bad math"
     line = f"{tab}# In sum, these tests covered {pct}% of {func_name}'s lines\n"
     header.append(line)
     if pct < 100:
         uncovered_str = function_metadata.get_all_uncovered_line_str()
         lines = [
-                    f"{tab}# Line(s) not covered by ANY of the tests below:\n",
-                    f"{tab}# {uncovered_str}\n"
-                ]
+            f"{tab}# Line(s) not covered by ANY of the tests below:\n",
+            f"{tab}# {uncovered_str}\n",
+        ]
         header += lines
 
-    test_str_list_def_dict:typing.DefaultDict[int, List[str]] = defaultdict(int) # type: ignore [arg-type]
+    test_str_list_def_dict: typing.DefaultDict[int, List[str]] = defaultdict(int)  # type: ignore [arg-type]
     # Only functions/methods that accessed global
     # variables will need to be patched
     # The variable below will help us keep track of this.
     needs_monkeypatch = False
     package = Path(source_file).stem
     initial_import_list = get_module_import_string(source_file).split(".")
     initial_import_prefix = ".".join(initial_import_list[:-1])
     initial_import_suffix = initial_import_list[-1]
     if initial_import_prefix:
-        initial_import = f"from {initial_import_prefix} import {initial_import_suffix}\n"
+        initial_import = (
+            f"from {initial_import_prefix} import {initial_import_suffix}\n"
+        )
     elif initial_import_suffix:
         initial_import = f"import {initial_import_suffix}\n"
     else:
         initial_import = ""
 
     item = "globals"
     for hash_key_index, hash_key in enumerate(sorted(state)):
-        test_str_list = [f"def test_{func_name.replace('.','_')}_{hash_key_index}():\n",
-                         f"{tab}monkeypatch = MonkeyPatch()\n"]
+        test_str_list = [
+            f"def test_{func_name.replace('.','_')}_{hash_key_index}():\n",
+            f"{tab}monkeypatch = MonkeyPatch()\n",
+        ]
         monkey_patches = []
-        coverage_list = gen_coverage_list(  function_metadata,
-                                            state[hash_key].coverage,
-                                            func_name,
-                                            tab)
+        coverage_list = gen_coverage_list(
+            function_metadata, state[hash_key].coverage, func_name, tab
+        )
         # Due to some complexity of self-testing (e.g. bugs I can't yet squash)
         # coverage_str might be empty.  That's fine, so continue
         if not coverage_list:
             continue
-        coverage_str = ''.join(coverage_list)
+        coverage_str = "".join(coverage_list)
         test_str_list.append(coverage_str)
-        #test_str_list += f'{tab}# Coverage: {state[hash_key].coverage}\n'
-
-        #print(f"{state[hash_key].keys()}")
+        # test_str_list += f'{tab}# Coverage: {state[hash_key].coverage}\n'
+
+        # print(f"{state[hash_key].keys()}")
         for k in sorted(state[hash_key].globals_before):
             needs_monkeypatch = True
             v = state[hash_key][k]
             v = normalize_arg(v)
             test_str_list.append(f"{tab}{k} = {v}\n")
-            line = f'{tab}monkeypatch.setattr({package}, \"{k}\", {k})\n'
+            line = f'{tab}monkeypatch.setattr({package}, "{k}", {k})\n'
             monkey_patches.append(line)
         if monkey_patches:
             test_str_list += monkey_patches
-        #monkey_patches = []
+        # monkey_patches = []
         test_str_list.append(f"{tab}args = []\n")
         is_method = function_metadata.is_method
         logger.debug("%s is method: %s", func_name, is_method)
 
         # Remove the 'self' argument from the arg list if this
         # decoratee is a class method (as opposed to a regular function)
         for arg in state[hash_key].args:
             # TODO If an arg is a class, construct it
-            #if not isinstance(arg, str):
+            # if not isinstance(arg, str):
             #    unpacked_args.append(f"{arg}")
-            #else:
+            # else:
             #    unpacked_args.append(arg)
             test_str_list.append(f"{tab}args.append({arg})\n")
-        #logger.debug("unpacked_args=%s", unpacked_args)
-        #unpacked_args = ','.join(unpacked_args)
+        # logger.debug("unpacked_args=%s", unpacked_args)
+        # unpacked_args = ','.join(unpacked_args)
 
         this_result_type = function_metadata.result_types[hash_key]
-        test_str_list += meta_program_function_call(state[hash_key],
-                                                        tab,
-                                                        package,
-                                                        func_name,
-                                                        this_result_type)
+        test_str_list += meta_program_function_call(
+            state[hash_key], tab, package, func_name, this_result_type
+        )
         dict_get = ".__dict__.get"
         for k in sorted(state[hash_key].globals_after):
             v = state[hash_key].globals_after[k]
             v = normalize_arg(v)
 
-            if v in ['None', '[]', '{}']:
-                line = f'{tab}assert not {package}{dict_get}(\"{k}\")\n'
+            if v in ["None", "[]", "{}"]:
+                line = f'{tab}assert not {package}{dict_get}("{k}")\n'
                 line = re.sub("<class '([^']+)'>", "\\1", line)
                 test_str_list.append(line)
                 needs_monkeypatch = True
                 continue
 
             # Define a local variable with the
             # same name and valueas to one being asserted
             test_str_list.append(f"{tab}modified_{k} = {v}\n")
             # Now assert that that variable exists in the global namespace
-            line = f'{tab}assert {package}{dict_get}(\"{k}\") == modified_{k}\n'
+            line = f'{tab}assert {package}{dict_get}("{k}") == modified_{k}\n'
             line = re.sub("<class '([^']+)'>", "\\1", line)
             test_str_list.append(line)
             needs_monkeypatch = True
-
-
 
         # What if a global variable is written to but not read from?
         # handle that here, otherwise I'd have to put this code in the loop above
         if not needs_monkeypatch:
             test_str_list[1] = ""
 
-        #test_str_list += monkey_patches
+        # test_str_list += monkey_patches
         # Delete all references to "__main__", it's needless
-        #print(test_str_list)
+        # print(test_str_list)
         test_str_list = [re.sub("__main__.", "", x) for x in test_str_list]
         if not test_str_list:
             # If this function was never executed, its coverage is 0%
             # Raise an exception to alert the user
             # Note that we don't need any imports at all
-            test_str_list.append(f"{tab}raise Exception('Empty test - this function was never executed')")
+            test_str_list.append(
+                f"{tab}raise Exception('Empty test - this function was never executed')"
+            )
 
         if test_str_list:
             test_str_list_def_dict[hash_key_index] = test_str_list
             was_executed = True
 
@@ -1587,11 +1694,15 @@
     # global variables will need to be patched
     if needs_monkeypatch:
         imports.append("from _pytest.monkeypatch import MonkeyPatch\n")
 
     custom_imports = []
-    logger.debug("func_name=%s\nfunction_metadata.types_in_use=%s", func_name, function_metadata.types_in_use)
+    logger.debug(
+        "func_name=%s\nfunction_metadata.types_in_use=%s",
+        func_name,
+        function_metadata.types_in_use,
+    )
     for this_type in function_metadata.types_in_use:
         continue_flag = False
         for other_type in function_metadata.types_in_use:
             if this_type == other_type:
                 continue
@@ -1599,11 +1710,11 @@
                 continue_flag = True
                 break
         if continue_flag:
             continue
         splits = this_type.split(".")
-        prefix = '.'.join(splits[:-1])
+        prefix = ".".join(splits[:-1])
         module = splits[-1]
         if not module:
             logger.error("NO MODULE")
             continue
         if prefix == "__main__":
@@ -1618,30 +1729,29 @@
         imports.append("\n")
         imports.append(f"# Now import modules specific to {func_name}:\n")
     imports += custom_imports
 
     logger.debug("func_name=%s", func_name)
-    result_file_str = f"test_{func_name}.py"#.replace('.','_')}.py"
+    result_file_str = f"test_{func_name}.py"  # .replace('.','_')}.py"
     result_file_str = re.sub("__init__", "constructor", result_file_str)
     result_file = tests_dir.joinpath(result_file_str)
 
-
-    #final_result = ''.join(y for y in x for x in test_str_list_def_dict.values())
-    #print(final_result)
-    #final_result_bytes = "".join([x for x in final_result]).encode()
-    #logger.critical(final_result)
+    # final_result = ''.join(y for y in x for x in test_str_list_def_dict.values())
+    # print(final_result)
+    # final_result_bytes = "".join([x for x in final_result]).encode()
+    # logger.critical(final_result)
 
     if "pytest" in sys.modules:
         """
         Return hash of resulting string here,
         this is used when self-testing auto_generate_tests with
         unit_test_generator_decorator
         """
-        h = hashlib.new('sha256')
+        h = hashlib.new("sha256")
         h.update(str(sorted(test_str_list_def_dict.items())).encode())
         return h.digest().hex()
-        #return str(sorted(test_str_list_def_dict.items()))#final_result_bytes
+        # return str(sorted(test_str_list_def_dict.items()))#final_result_bytes
 
     with open(result_file, "w", encoding="utf-8") as st:
         for list in [imports, header]:
             if list:
                 st.writelines(list)
@@ -1651,22 +1761,19 @@
     logger.info("Wrote to %s", result_file)
 
     # Format the generated Python file with black for easier reading
 
     try:
-        subprocess.run( f"black {result_file}".split(),
-                        check=True,
-                        capture_output=True
-                        )
+        subprocess.run(f"black {result_file}".split(), check=True, capture_output=True)
     except CalledProcessError as e:
         logger.error("Got Error running black formatter on %s:", result_file)
-        logger.error("%s", pp.pformat(e)+"\n")
-        logger.error("%s", e.stderr.decode()+"\n")
+        logger.error("%s", pp.pformat(e) + "\n")
+        logger.error("%s", e.stderr.decode() + "\n")
         if e.stdout:
             logger.error(e.stdout.decode())
 
     logger.info("Re-formatted %s with black formatter", result_file)
 
     # Return hash of resulting string here
-    h = hashlib.new('sha256')
+    h = hashlib.new("sha256")
     h.update(str(sorted(test_str_list_def_dict.items())).encode())
     return h.digest().hex()
