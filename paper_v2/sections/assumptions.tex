\section{Assumptions}\label{sec:assumptions}

An initial assumption of the author's hypothesis is that all code executing under the
functional test is mostly correct, as the inputs and outputs from each
function called during the functional test would become data for the
unit tests.  

That said, the author acknowledges that software engineers may not 
wish to assume that an apparently working functional test indicates accuracy of 
all internally executed components. Regardless, the creation of such unit 
tests would still provide a syntactically accurate unit
test file for the software engineer to start from, rather than create each unit
test from scratch.  

In addition to saving time from creating the test
boilerplate, the true expense saved is that of manually defining the desired
inputs and correct outputs.  This author believes there is value in this automated
approach even if the generated tests must still be verified for accuracy,
as in the author's experience it was faster in some cases to manually inspect 
the resulting unit test code for accuracy than develop and verify unit tests from scratch.

Another assumption required for successful execution is that the \textit{repr()} method
of each object generates valid Python code that can be used to re-create that
object, or that such a function can be developed and used to temporarily
overwrite a \textit{repr\(\)} method not meeting this requirement.  The author demonstrates
this in the repository code by overwriting the \textit{repr\(\)} method of the
Pandas DataFrame class as shown in Listing~\ref{lst:pandas_repr}.

\lstinputlisting[%
language=Python,%
numbers=left,
caption={Overwriting incompatible \textit{repr} method},%
label={lst:pandas_repr},%
]{examples/pandas\_repr.py}
